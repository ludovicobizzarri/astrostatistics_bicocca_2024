{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import astroML\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import optimize\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from astroML import stats as astroMLstats\n",
    "from astropy.visualization.hist import hist as fancyhist\n",
    "\n",
    "# astropy\n",
    "from astropy import units as u\n",
    "from astropy import constants\n",
    "\n",
    "# density estimation\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import emcee\n",
    "#import pymc3\n",
    "import corner\n",
    "\n",
    "import dynesty\n",
    "\n",
    "import sklearn\n",
    "from sklearn import manifold\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dimensional reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from astroML.linear_model import PolynomialRegression\n",
    "from astroML.linear_model import BasisFunctionRegression\n",
    "from astroML.linear_model import NadarayaWatson\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Regularization\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from astroML.utils import split_samples, completeness_contamination\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from astroML.classification import GMMBayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxies vs Quasars with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our galaxy vs quasar data we've used in a previous exercise. \n",
    "\n",
    "1. Read in SDSS galaxy color data from `solutions/galaxyquasar.csv`. Create arrays for the $(u-g)$, $(g-r)$, $(r-i)$, and $(i-z)$ colors. Also create an array with the class labels where galaxy=$0$ and quasar=$1$. \n",
    "\n",
    "2. Now we're going to fit a neural network classifier. First, scale your data appropriately and do a 30% train/test split.\n",
    "\n",
    "3. Now train the classifier. Use one the package among those we've seen. These include Tensorflow via keras, pytorch, and the [multilayer perceptron classifier](sklearn.neural_network.MLPClassifier) implemented in scikit-learn. My solution uses the latter, but this is an opportunity to pick the one you're most interested in learning. \n",
    "\n",
    "3. Start from a network architecture with a single hidden layer with 5 neurons, using the `adam` solver, the `relu` activation function, and a learninig rate of `0.001`. Plot the resulting ROC curve. \n",
    "\n",
    "4. Now let's optimize the hyperparameters of your network. Explore different hyperparameters and see what fits the data best.  Do your best now to optimize the network architecture. Be creative!\n",
    "\n",
    "5. Is your best result comparable with the simpler classifiers we've seen before? Do we need deep learning here? If yes, which features are captured best?\n",
    "\n",
    "\n",
    "A few tips:\n",
    "\n",
    "- In scikit-learn, remember that you can utilize all availables cores on your machine with `n_jobs=-1`. Print out the classification score for the training data, and the best parameters obtained by the cross validation.\n",
    "- If it takes too long, run the hyperparameter optimization on a subset of the training set. Then retrain the full network using the best hyperparameters only.\n",
    "- On cross validation, for scikit learn we've seen how to use `GridSearchCV` already. For Tensorflow, there's a really cool tool called [Tensorboard](https://www.tensorflow.org/tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "      <th>z1</th>\n",
       "      <th>zerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.97213</td>\n",
       "      <td>18.53676</td>\n",
       "      <td>18.58280</td>\n",
       "      <td>18.34936</td>\n",
       "      <td>18.29215</td>\n",
       "      <td>QSO</td>\n",
       "      <td>0.522819</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.24592</td>\n",
       "      <td>17.47646</td>\n",
       "      <td>16.47817</td>\n",
       "      <td>16.04472</td>\n",
       "      <td>15.68851</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.43536</td>\n",
       "      <td>17.70268</td>\n",
       "      <td>16.91565</td>\n",
       "      <td>16.58327</td>\n",
       "      <td>16.39128</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.31626</td>\n",
       "      <td>18.18312</td>\n",
       "      <td>17.39591</td>\n",
       "      <td>16.94549</td>\n",
       "      <td>16.65395</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.147435</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.28828</td>\n",
       "      <td>19.11188</td>\n",
       "      <td>18.88937</td>\n",
       "      <td>18.80013</td>\n",
       "      <td>18.49183</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.011455</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>19.37295</td>\n",
       "      <td>18.12382</td>\n",
       "      <td>17.39886</td>\n",
       "      <td>16.98503</td>\n",
       "      <td>16.70585</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>18.52021</td>\n",
       "      <td>16.88262</td>\n",
       "      <td>16.03280</td>\n",
       "      <td>15.56884</td>\n",
       "      <td>15.22454</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.085063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>18.62718</td>\n",
       "      <td>17.30876</td>\n",
       "      <td>16.87371</td>\n",
       "      <td>16.62399</td>\n",
       "      <td>16.42296</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>19.55140</td>\n",
       "      <td>18.27711</td>\n",
       "      <td>17.62101</td>\n",
       "      <td>17.21947</td>\n",
       "      <td>17.03347</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.112571</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>18.80772</td>\n",
       "      <td>17.75751</td>\n",
       "      <td>17.40500</td>\n",
       "      <td>17.21650</td>\n",
       "      <td>17.12295</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              u         g         r         i         z   class        z1  \\\n",
       "0      18.97213  18.53676  18.58280  18.34936  18.29215     QSO  0.522819   \n",
       "1      19.24592  17.47646  16.47817  16.04472  15.68851  GALAXY  0.122846   \n",
       "2      19.43536  17.70268  16.91565  16.58327  16.39128  GALAXY  0.000000   \n",
       "3      19.31626  18.18312  17.39591  16.94549  16.65395  GALAXY  0.147435   \n",
       "4      19.28828  19.11188  18.88937  18.80013  18.49183     QSO  2.011455   \n",
       "...         ...       ...       ...       ...       ...     ...       ...   \n",
       "49995  19.37295  18.12382  17.39886  16.98503  16.70585  GALAXY  0.113016   \n",
       "49996  18.52021  16.88262  16.03280  15.56884  15.22454  GALAXY  0.085063   \n",
       "49997  18.62718  17.30876  16.87371  16.62399  16.42296  GALAXY  0.054429   \n",
       "49998  19.55140  18.27711  17.62101  17.21947  17.03347  GALAXY  0.112571   \n",
       "49999  18.80772  17.75751  17.40500  17.21650  17.12295  GALAXY  0.043652   \n",
       "\n",
       "           zerr  \n",
       "0      0.000155  \n",
       "1      0.000028  \n",
       "2      0.000000  \n",
       "3      0.000009  \n",
       "4      0.000631  \n",
       "...         ...  \n",
       "49995  0.000011  \n",
       "49996  0.000014  \n",
       "49997  0.000008  \n",
       "49998  0.000009  \n",
       "49999  0.000007  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('galaxyquasar-Copy1.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GALAXY' 'QSO']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "      <th>z1</th>\n",
       "      <th>zerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.97213</td>\n",
       "      <td>18.53676</td>\n",
       "      <td>18.58280</td>\n",
       "      <td>18.34936</td>\n",
       "      <td>18.29215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522819</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.24592</td>\n",
       "      <td>17.47646</td>\n",
       "      <td>16.47817</td>\n",
       "      <td>16.04472</td>\n",
       "      <td>15.68851</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.43536</td>\n",
       "      <td>17.70268</td>\n",
       "      <td>16.91565</td>\n",
       "      <td>16.58327</td>\n",
       "      <td>16.39128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.31626</td>\n",
       "      <td>18.18312</td>\n",
       "      <td>17.39591</td>\n",
       "      <td>16.94549</td>\n",
       "      <td>16.65395</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147435</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.28828</td>\n",
       "      <td>19.11188</td>\n",
       "      <td>18.88937</td>\n",
       "      <td>18.80013</td>\n",
       "      <td>18.49183</td>\n",
       "      <td>1</td>\n",
       "      <td>2.011455</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>19.37295</td>\n",
       "      <td>18.12382</td>\n",
       "      <td>17.39886</td>\n",
       "      <td>16.98503</td>\n",
       "      <td>16.70585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113016</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>18.52021</td>\n",
       "      <td>16.88262</td>\n",
       "      <td>16.03280</td>\n",
       "      <td>15.56884</td>\n",
       "      <td>15.22454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085063</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>18.62718</td>\n",
       "      <td>17.30876</td>\n",
       "      <td>16.87371</td>\n",
       "      <td>16.62399</td>\n",
       "      <td>16.42296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>19.55140</td>\n",
       "      <td>18.27711</td>\n",
       "      <td>17.62101</td>\n",
       "      <td>17.21947</td>\n",
       "      <td>17.03347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112571</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>18.80772</td>\n",
       "      <td>17.75751</td>\n",
       "      <td>17.40500</td>\n",
       "      <td>17.21650</td>\n",
       "      <td>17.12295</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              u         g         r         i         z  class        z1  \\\n",
       "0      18.97213  18.53676  18.58280  18.34936  18.29215      1  0.522819   \n",
       "1      19.24592  17.47646  16.47817  16.04472  15.68851      0  0.122846   \n",
       "2      19.43536  17.70268  16.91565  16.58327  16.39128      0  0.000000   \n",
       "3      19.31626  18.18312  17.39591  16.94549  16.65395      0  0.147435   \n",
       "4      19.28828  19.11188  18.88937  18.80013  18.49183      1  2.011455   \n",
       "...         ...       ...       ...       ...       ...    ...       ...   \n",
       "49995  19.37295  18.12382  17.39886  16.98503  16.70585      0  0.113016   \n",
       "49996  18.52021  16.88262  16.03280  15.56884  15.22454      0  0.085063   \n",
       "49997  18.62718  17.30876  16.87371  16.62399  16.42296      0  0.054429   \n",
       "49998  19.55140  18.27711  17.62101  17.21947  17.03347      0  0.112571   \n",
       "49999  18.80772  17.75751  17.40500  17.21650  17.12295      0  0.043652   \n",
       "\n",
       "           zerr  \n",
       "0      0.000155  \n",
       "1      0.000028  \n",
       "2      0.000000  \n",
       "3      0.000009  \n",
       "4      0.000631  \n",
       "...         ...  \n",
       "49995  0.000011  \n",
       "49996  0.000014  \n",
       "49997  0.000008  \n",
       "49998  0.000009  \n",
       "49999  0.000007  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the color arrays\n",
    "u_g, g_r, r_i, i_z = np.array([(data['u']-data['g']), (data['g']-data['r']), (data['r']-data['i']), (data['i']-data['z'])])\n",
    "\n",
    "# assign the 0 to galaxyes and 1 to QSO\n",
    "le = LabelEncoder()\n",
    "# Assign unique integers from 0 to 6 to each star type\n",
    "data['class'] = le.fit_transform(data['class'])\n",
    "labels = le.inverse_transform(data['class'])\n",
    "class_names = le.classes_\n",
    "print(class_names)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([u_g, g_r, r_i, i_z]).T\n",
    "y = np.array(data['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=0.3,train_size=0.7)\n",
    "\n",
    "# rescale the data:\n",
    "Xtrain_scaled = preprocessing.scale(X_train)\n",
    "Xtest_scaled = preprocessing.scale(X_test)\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_idx = np.array(data['class']==0)\n",
    "qso_idx = np.array(data['class']==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 5), (5, 1)]\n",
      "accuracy: 0.9840666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "clf_nn = MLPClassifier(hidden_layer_sizes=(5),solver='sgd',activation='logistic', # grad descent solver and sigmoid activation funct\n",
    "                       learning_rate='constant', learning_rate_init=0.001,\n",
    "                       random_state=1, max_iter=5000)\n",
    "\n",
    "clf_nn.fit(Xtrain_scaled, y_train)\n",
    "\n",
    "# Look at the weights\n",
    "print([coef.shape for coef in clf_nn.coefs_])\n",
    "\n",
    "y_pred = clf_nn.predict(Xtest_scaled)\n",
    "\n",
    "# accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print('accuracy:',accuracy)\n",
    "\n",
    "proba = clf_nn.predict_proba(Xtest_scaled)[:,1]\n",
    "fpr, tpr, thresh = roc_curve(y_test, proba)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(fpr, tpr,color='black')\n",
    "plt.xlabel(r'$fpr$')\n",
    "plt.ylabel(r'$tpr$')\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation to determine the best number of layers and the best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = np.array([np.arange(1,5),np.arange(1,5)])\n",
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best N_layers: 10\n",
      "best learning raee: 0.0089\n"
     ]
    }
   ],
   "source": [
    "# define the NN classifier\n",
    "clf_grid = MLPClassifier(solver='sgd',activation='logistic',learning_rate='constant',\n",
    "            random_state=1, max_iter=5000)\n",
    "\n",
    "# define the grid of layers and learning rates:\n",
    "n_layers = np.arange(1,11)\n",
    "learn_rates = np.linspace(0.0001,0.01,10)\n",
    "solver_arr = np.array(['lbfgs', 'sgd', 'adam'])\n",
    "activation_arr = np.array(['identity', 'logistic', 'tanh', 'relu'])\n",
    "l_rate = np.array(['constant','adaptive']) \n",
    "\n",
    "grid = GridSearchCV(clf_grid, param_grid={'hidden_layer_sizes': n_layers, 'learning_rate_init':learn_rates,\n",
    "                                          'solver': solver_arr, 'activation': activation_arr,\n",
    "                                          'learning_rate': l_rate}, cv=5, n_jobs=-1) \n",
    "\n",
    "grid.fit(Xtrain_scaled,y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best N_layers: 10\n",
      "best learning rate: 0.0089\n",
      "best solver: adam\n",
      "best activation function: tanh\n",
      "best learning method: constant\n"
     ]
    }
   ],
   "source": [
    "best_rate = grid.best_params_['learning_rate_init']\n",
    "best_layer = grid.best_params_['hidden_layer_sizes']     \n",
    "best_solver = grid.best_params_['solver']\n",
    "best_activation = grid.best_params_['activation']\n",
    "best_learn_rate = grid.best_params_['learning_rate']\n",
    "\n",
    "print('best N_layers:',best_layer)\n",
    "print('best learning rate:',best_rate)\n",
    "print('best solver:',best_solver)\n",
    "print('best activation function:',best_activation)\n",
    "print('best learning method:',best_learn_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 10), (10, 1)]\n",
      "accuracy cross_validated: 0.9848666666666667\n",
      "accuracy basic NN: 0.9840666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAGHCAYAAAC03PVAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfh0lEQVR4nO3df7xVdZ3v8deHH0bdDErQVCDILAX5keKPSQvMqcTJMRszIC37xWjDOHRriqsz5WSZmZVamVJ5sbrIFP2QzKmrY+LNH404IYmGkpKc8AfqaKmDinzuH3uD53vYh3MOnLP2OZzX8/E4D/da67vX/nwPx+97f9fae63ITCRJ2mxAswuQJPUuBoMkqWAwSJIKBoMkqWAwSJIKBoMkqWAwSL1ARJwVEd9rdh0SGAxqoohYExH/HRFPRsSDEbEgIl7aps0bIuK6iPhzRDwRET+NiHFt2rwsIi6IiPvr+1pdXx5ebY96l4gYExEZEYO20easept3tVo3qL5uTH15QX35kFZtXhMRfglqJ2UwqNmOzcyXApOB1wP/a/OGiPgL4P8CVwJ7AWOB24EbI+LV9Ta7AP8OjAeOBl4GvAF4FNgykHW3bQ22fdBjwGciYmAHbT5bUT1qMoNBvUJmPgj8glpAbHYe8J3MvDAz/5yZj2XmPwG3AGfV27wXGA0cn5l3ZuamzHw4M8/OzKsbvVZEjI+IayLisYh4KCLOqK9fEBGfbdVuWkS0tFpeExGfjIgVwFMR8U8RsbjNvi+MiIvqj4dGxLcj4oGI+GNEfLaDwXdIRPxrfXb0nxExqdV+94qIH0bE+oi4LyJOb7XtkIhYFhF/qvfny/VNN9T/+3h9JvUX7bzuz4FngZO2UdvlwMSImLqNNtpJGAzqFSJiJDAdWF1ffgm1d/4/aND8+8Bb6o//Evh5Zj7ZydfZFbiW2mC4F/AaajOOzpoJ/BUwDPgucExEvKy+74HAicDCetvLgY3113g98FbgQ9vY93HU+vuK+j5+EhGDI2IA8FNqs6W9gaOAuRHxtvrzLgQuzMyXAftQ+/0AvKn+32GZ+dLMvLmd103gn4FPR8Tgdto8DZwDfG4b9WsnYTCo2X4SEX8G1gIPA5+ur38Ftb/PBxo85wFg8/mD3dpp0563Aw9m5pcyc0N9JvLrLjz/osxcm5n/nZl/AP4TeEd925uBpzPzlojYg1rQzc3MpzLzYeArwIxt7Pu2zFycmc8BXwaGAIcBBwMjMvMzmflsZt4LfLPVvp4DXhMRwzPzycy8pQv9ASAzlwDr2XZwXQqMjojpXd2/+haDQc32jszcFZgG7McLA/5/AZuAPRs8Z0/gkfrjR9tp055RwO+3q9KatW2WF1KbRQDM4oXZwquAwcADEfF4RDxObWDdvTP7zsxNQAu1Wc2rgL0276e+rzOAPerNPwi8FvhdRNwaEW/fzr79E3AmtUDaSmY+A5xd/4ntfA31AQaDeoXMXAosAM6vLz8F3Ay8q0HzE3nh8M+1wNsi4n908qXWUjvc0shTwEtaLb+yUaltln8ATKsfCjueF4JhLfAMMDwzh9V/XpaZ47dR26jND+qHj0YC6+r7uq/VfoZl5q6ZeQxAZt6TmTOphc4XgMX130eXPjWUmddQO5T3kW00+9/A0HpftZMyGNSbXAC8JSIm15fnAe+LiNMjYteIeHn95PBfAP9Sb/NdagPnDyNiv4gYEBG7RcQZEXFMg9e4CnhlRMyNiBfV93tofdtyaucMXhERrwTmdlRwZq4Hrqc2YN6XmXfV1z9A7RNVX6p/nHZAROzTwcnbgyLinfVPPM2lFiy3AP8B/Kl+4vvFETEwIg6IiIMBIuKkiBhRn2U8Xt/X89QODW0CXt1RP1o5E/jENvq7kdqJ/092YZ/qYwwG9Rr1QfY71E6Ekpm/At4GvJPaeYQ/UDuJe0Rm3lNv8wy1E9C/A64B/kRtIB0ObHXuIDP/TO3E9bHAg8A9wJH1zd+ldoJ3DbVB/V87WfrCeg0L26x/L7ALcCe1Q2OL2fZhryuBd9fbngy8MzOfy8zn6/VOBu6jdhjtW9TeuUPtY7orI+JJaieiZ9TPnzxN7WTxjfVDUId11JHMvJHa729brqBr53XUx4Q36pEkteaMQZJUMBgkSQWDQZJUMBgkSQWDQZJU6PNXiBw+fHiOGTOm2WVIUp9y2223PZKZIxpt6/PBMGbMGJYtW9bsMiSpT4mIP7S3zUNJkqSCwSBJKhgMkqSCwSBJKhgMkqSCwSBJKhgMkqSCwSBJKhgMkqRCZcEQEZdFxMMRcUc72yMiLoqI1RGxIiIOrKo2SdILqpwxLKB2C8L2TAf2rf/MBr5RQU2SpDYqu1ZSZt4QEWO20eQ44DtZu9foLRExLCL2rN9UXZJ6xvz5sLDt7bp7v7mrV8OIEVzwm990+75700X09gbWtlpuqa/bKhgiYja1WQWjR4+upDip3+ujA2iHli6t/Xfq1Iab569bx8KHH66woM5Z+sQTNK54x/WmYIgG67JRw8ycD8wHmDJlSsM2qtjOOmjoBR0MoI301kG1MHQo7LFHu5uX3nMPAFO70O8qTAVmzZrVI/vuTcHQAoxqtTwSWNekWvquZg3Q2zFoqPdqOKB3MIA20lsH1a6YOnUqs2bNYvbs2c0upTK9KRiWAHMiYhFwKPBEvzu/0B2DerMG6KlTYdYs6Ef/8/QV8+fPZ2EX/666a0Dvj4PqzqCyYIiIK4BpwPCIaAE+DQwGyMxLgKuBY4DVwNPA+6uqrcd1dsDvjkHdAbpP2J7Benstrf9ddWWQd0Dv36L2IaC+a8qUKdmr7uDWKAS6MuA7qFemysG5re0ZrHeEg7zaiojbMnNKo2296VBS39LeLKBRCOxk7+KbOaB2p6oH59Z8R67ezGDoSFcCYPNyHwyBrgz2zRxQu5ODs9SYwdCezYHQCwOgJ96xd2Wwd0CVdm4GQ3sWLoTly3c4AJo9iHeWg72kzQyGtjbPFJYvh8mT4frr22nWuQHfQVxSX2MwtDZ/Pvzt39Yeb54p0DgEOjvgO4hL6msMhs1ah8Kll8Ls2bVAmDatYQg44EvaWRkMm22eEVx6KfNhq0AwBCT1FwYD1GYLS5cyf999WbhwoYEgqV8zGAAWLmQ+8Lf33AP33GMgSOrXDAZqV5Ksn13g0ksvNRAk9WtV3tqz19p8eWFDQZIMhi2mDh1qKEgSBkPtxPMTTzS7CknqNfp9MMw//3yWQpfvTCVJO6t+Hwybzy/M+tjHmlyJJPUO/T4YwPMLktSawSBJKhgMkqSCwSBJKhgMkqSCwSBJKhgMkqSCwSBJKhgMkqRC/w4Gr5MkSVvp38Gw+XaeXidJkrbo38EAMHQo7Llns6uQpF7DYJAkFQwGSVLBYJAkFQwGSVLBYJAkFQwGSVKhXwfD/HXrWOoX3CSp0K+DYcv9nmfNanIlktR79OtgAO/3LElt9ftgkCSVDAZJUsFgkCQVDAZJUsFgkCQVDAZJUsFgkCQVDAZJUsFgkCQVDAZJUsFgkCQVDAZJUsFgkCQVKg2GiDg6IlZFxOqImNdg+9CI+GlE3B4RKyPi/VXWJ0mqMBgiYiDwdWA6MA6YGRHj2jT7O+DOzJwETAO+FBG7VFWjJKnaGcMhwOrMvDcznwUWAce1aZPArhERwEuBx4CNFdYoSf1elcGwN7C21XJLfV1rXwP2B9YBvwX+ITM3VVOeJAmqDYZosC7bLL8NWA7sBUwGvhYRL9tqRxGzI2JZRCxbv359d9cpSf1alcHQAoxqtTyS2sygtfcDP8qa1cB9wH5td5SZ8zNzSmZOGTFiRI8VLEn9UZXBcCuwb0SMrZ9QngEsadPmfuAogIjYA3gdcG+FNUpSvzeoqhfKzI0RMQf4BTAQuCwzV0bEqfXtlwBnAwsi4rfUDj19MjMfqapGSVKFwQCQmVcDV7dZd0mrx+uAt1ZZkySp5DefJUkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEmFSoMhIo6OiFURsToi5rXTZlpELI+IlRGxtMr6JEkwqKoXioiBwNeBtwAtwK0RsSQz72zVZhhwMXB0Zt4fEbtXVZ8kqabKGcMhwOrMvDcznwUWAce1aTML+FFm3g+QmQ9XWJ8kiWqDYW9gbavllvq61l4LvDwiro+I2yLivY12FBGzI2JZRCxbv359D5UrSf1TlcEQDdZlm+VBwEHAXwFvA/45Il671ZMy52fmlMycMmLEiO6vVJL6scrOMVCbIYxqtTwSWNegzSOZ+RTwVETcAEwC7q6mRElSlTOGW4F9I2JsROwCzACWtGlzJfDGiBgUES8BDgXuqrBGSer3KpsxZObGiJgD/AIYCFyWmSsj4tT69ksy866I+DmwAtgEfCsz76iqRklStYeSyMyrgavbrLukzfIXgS9WWZck6QV+81mSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEmFTgVDRAyIiDN6uhhJUvN1KhgycxPwlz1ciySpF+jKoaTfRMSnI8LDT5K0ExvUhbajgAnAaRHxa2AFsCIzf9AjlUmSmqLTwZCZJwJExIuA8dRC4hDAYJCknUhXZgwAZOYzwH/WfyRJO5lOny+IiOkR8euIWBUR34+Iw3qyMElSc3TlRPLFwP8EDgPmA+dHxMweqUqS1DRdOZT0UGbeWH98bUTcDPwauKL7y5IkNUtXZgxrIuKzEbFLffk54M89UJMkqYm6+p2EdwJrI+JXwGrg+ojYt/vLkiQ1S1cOJb02M8dFxIupfVx1MvAu4A0R8erMHNUTBUqSqtVhMETEicCBwK4RsT9wd2YuA5ZFxOmZObGni5QkVaczM4YbgSHAh4AvA6+LiMeBdcB/91xpkqRm6DAYMvOPwHci4vebP5UUEa8AxgK/6+H6JEkV68olMW5s9fgx4LEeqUiS1FReKVWSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEmFSoMhIo6OiFURsToi5m2j3cER8XxEnFBlfZKkCoMhIgYCXwemA+OAmRExrp12XwB+UVVtkqQXVDljOARYnZn3ZuazwCLguAbt/h74IfBwhbVJkuqqDIa9gbWtllvq67aIiL2B44FLtrWjiJgdEcsiYtn69eu7vVBJ6s+qDIZosC7bLF8AfDIzn9/WjjJzfmZOycwpI0aM6K76JEnAoApfqwUY1Wp5JLCuTZspwKKIABgOHBMRGzPzJ5VUKEmqNBhuBfaNiLHAH4EZwKzWDTJz7ObHEbEAuMpQkKRqVRYMmbkxIuZQ+7TRQOCyzFwZEafWt2/zvIIkqRpVzhjIzKuBq9usaxgImXlKFTVJkkp+81mSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEkFg0GSVDAYJEmFSoMhIo6OiFURsToi5jXY/p6IWFH/uSkiJlVZnySpwmCIiIHA14HpwDhgZkSMa9PsPmBqZk4EzgbmV1WfJKmmyhnDIcDqzLw3M58FFgHHtW6QmTdl5n/VF28BRlZYnySJaoNhb2Btq+WW+rr2fBD4tx6tSJK0lUEVvlY0WJcNG0YcSS0Yjmhn+2xgNsDo0aO7qz5JEtXOGFqAUa2WRwLr2jaKiInAt4DjMvPRRjvKzPmZOSUzp4wYMaJHipWk/qrKYLgV2DcixkbELsAMYEnrBhExGvgRcHJm3l1hbZKkusoOJWXmxoiYA/wCGAhclpkrI+LU+vZLgE8BuwEXRwTAxsycUlWNkqRqzzGQmVcDV7dZd0mrxx8CPlRlTZKkkt98liQVDAZJUsFgkCQVDAZJUqH/BsP8+fDEE82uQpJ6nf4bDAsX1v67xx7NrUOSepn+GwwAQ4fCnns2uwpJ6lX6dzBIkrZiMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCgaDJKlgMEiSCoOaXYAkdeS5556jpaWFDRs2NLuUPmfIkCGMHDmSwYMHd/o5BoOkXq+lpYVdd92VMWPGEBHNLqfPyEweffRRWlpaGDt2bKef56EkSb3ehg0b2G233QyFLooIdtttty7PtAwGSX2CobB9tuf3ZjBIUic8+OCDzJgxg3322Ydx48ZxzDHHcPfddzN27FhWrVpVtJ07dy7nnXdesW7NmjVEBF/96le3rJszZw4LFiwA4JRTTmHvvffmmWeeAeCRRx5hzJgxPdqn9hgMktSBzOT4449n2rRp/P73v+fOO+/knHPO4aGHHmLGjBksWrRoS9tNmzaxePFi3v3ud2+1n913350LL7yQZ599tuHrDBw4kMsuu6zH+tFZBoMkdeCXv/wlgwcP5tRTT92ybvLkybzxjW9k5syZRTDccMMNjBkzhle96lVb7WfEiBEcddRRXH755Q1fZ+7cuXzlK19h48aN3d+JLvBTSZL6lrlzYfny7t3n5MlwwQXtbr7jjjs46KCDGm6bOHEiAwYM4Pbbb2fSpEksWrSImTNntruvefPmMX36dD7wgQ9stW306NEcccQRfPe73+XYY4/tai+6jTMGSdpBm2cNGzdu5Morr+Rd73pXu23Hjh3LIYccwsKFCxtuP+OMM/jiF7/Ipk2beqrcDjljkNS3bOOdfU8ZP348ixcvbnf7zJkzeetb38rUqVOZOHEiu++++zb3d8YZZ3DCCSfwpje9aattr3nNa5g8eTLf//73d7ju7eWMQZI68OY3v5lnnnmGb37zm1vW3XrrrSxduhSAffbZh91224158+Zt8zDSZvvttx/jxo3jqquuarj9zDPP5Pzzz++e4reDwSBJHYgIfvzjH3PNNdewzz77MH78eM466yz22muvLW1mzpzJ7373O44//vhO7fPMM8+kpaWl4bbx48dz4IEHdkvt2yMys2kv3h2mTJmSy5Yt6/oTp01j2vLlMHky119/fXeXJakb3XXXXey///7NLqPPavT7i4jbMnNKo/bOGCRJBYNBklQwGCRJBYNBklQwGCRJBYNBklQwGCSpA2vWrOGAAw7Y4f0sWbKEc889t9Ptx4wZw9/8zd9sWV68eDGnnHIKAAsWLGDAgAGsWLFiy/YDDjiANWvW7HCdlQZDRBwdEasiYnVEzGuwPSLiovr2FRHRvG94SFI3++u//mvmzdtq6NumZcuWsXLlyobbRo4cyec+97nuKK1QWTBExEDg68B0YBwwMyLGtWk2Hdi3/jMb+EZP1TN/3TqWPvFET+1e0k5m48aNvO9972PixImccMIJPP300wB85jOf4eCDD+aAAw5g9uzZbP7S8EUXXcS4ceOYOHEiM2bMAGrv8ufMmQPAQw89xPHHH8+kSZOYNGkSN910U8PX/fjHP84555zTcNvb3/52Vq5cudWNgnZUlRfROwRYnZn3AkTEIuA44M5WbY4DvpO13+wtETEsIvbMzAe6u5iFDz8MwKxZs7p715J60Ny5c1nezZfdnjx5Mhd0cHG+VatW8e1vf5vDDz+cD3zgA1x88cV8/OMfZ86cOXzqU58C4OSTT+aqq67i2GOP5dxzz+W+++7jRS96EY8//vhW+zv99NOZOnUqP/7xj3n++ed58sknG77uiSeeyMUXX8zq1au32jZgwAA+8YlPcM4557R7j4ftUeWhpL2Bta2WW+rrutqGiJgdEcsiYtn69eu3q5jJY8fyD5MnM3v27O16vqT+ZdSoURx++OEAnHTSSfzqV78CajfxOfTQQ5kwYQLXXXfdlsM+EydO5D3veQ/f+973GDRo6/fg1113HaeddhpQu3Pb0KFDG77uwIED+cd//Ec+//nPN9w+a9YsbrnlFu67774d7uNmVc4YGt2Ruu2FmjrThsycD8yH2rWStqeYC37zm+15mqQm6+idfU+JiK2WN2zYwEc+8hGWLVvGqFGjOOuss9iwYQMAP/vZz7jhhhtYsmQJZ599drvnCTrj5JNP5vOf/zzjx4/fatugQYP42Mc+xhe+8IXt3n9bVc4YWoBRrZZHAuu2o40kVe7+++/n5ptvBuCKK67giCOO2BICw4cP58knn9xyz4ZNmzaxdu1ajjzySM477zwef/zxrQ4VHXXUUXzjG7XTqM8//zx/+tOf2n3twYMH89GPfrTdUDzllFO49tpr2d4jKG1VGQy3AvtGxNiI2AWYASxp02YJ8N76p5MOA57oifMLktRV+++/P5dffjkTJ07kscce47TTTmPYsGF8+MMfZsKECbzjHe/g4IMPBmoD/UknncSECRN4/etfz0c/+lGGDRtW7O/CCy/kl7/8JRMmTOCggw7qcEbxwQ9+sN17Qe+yyy6cfvrpPFw/d7qjKr3sdkQcA1wADAQuy8zPRcSpAJl5SdTmal8DjgaeBt6fmdu8pvZ2X3ZbUp/hZbd3TFcvu13prT0z82rg6jbrLmn1OIG/q7ImSVLJbz5LkgoGgySpYDBI6hP6+m2Im2V7fm8Gg6Reb8iQITz66KOGQxdlJo8++ihDhgzp0vMqPfksSdtj5MiRtLS0dNvn9PuTIUOGMHLkyC49x2CQ1OsNHjyYsWPHNruMfsNDSZKkgsEgSSoYDJKkQqWXxOgJEbEe+MN2Pn048Eg3ltMX2Of+wT73DzvS51dl5ohGG/p8MOyIiFjW3rVCdlb2uX+wz/1DT/XZQ0mSpILBIEkq9PdgmN/sAprAPvcP9rl/6JE+9+tzDJKkrfX3GYMkqY1+EQwRcXRErIqI1RExr8H2iIiL6ttXRMSBzaizO3Wiz++p93VFRNwUEZOaUWd36qjPrdodHBHPR8QJVdbXEzrT54iYFhHLI2JlRCytusbu1om/7aER8dOIuL3e5/c3o87uEhGXRcTDEXFHO9u7f/zKzJ36h9ptRH8PvBrYBbgdGNemzTHAvwEBHAb8utl1V9DnNwAvrz+e3h/63KrdddTuJHhCs+uu4N95GHAnMLq+vHuz666gz2cAX6g/HgE8BuzS7Np3oM9vAg4E7mhne7ePX/1hxnAIsDoz783MZ4FFwHFt2hwHfCdrbgGGRcSeVRfajTrsc2belJn/VV+8Beja5Rd7n878OwP8PfBDoHvumt5cnenzLOBHmXk/QGb29X53ps8J7Fq/h/xLqQXDxmrL7D6ZeQO1PrSn28ev/hAMewNrWy231Nd1tU1f0tX+fJDaO46+rMM+R8TewPHAJewcOvPv/Frg5RFxfUTcFhHvray6ntGZPn8N2B9YB/wW+IfM3FRNeU3R7eNXf7jsdjRY1/ajWJ1p05d0uj8RcSS1YDiiRyvqeZ3p8wXAJzPz+dqbyT6vM30eBBwEHAW8GLg5Im7JzLt7urge0pk+vw1YDrwZ2Ae4JiL+X2b+qYdra5ZuH7/6QzC0AKNaLY+k9k6iq236kk71JyImAt8CpmfmoxXV1lM60+cpwKJ6KAwHjomIjZn5k0oq7H6d/dt+JDOfAp6KiBuASUBfDYbO9Pn9wLlZOwC/OiLuA/YD/qOaEivX7eNXfziUdCuwb0SMjYhdgBnAkjZtlgDvrZ/dPwx4IjMfqLrQbtRhnyNiNPAj4OQ+/O6xtQ77nJljM3NMZo4BFgMf6cOhAJ37274SeGNEDIqIlwCHAndVXGd36kyf76c2QyIi9gBeB9xbaZXV6vbxa6efMWTmxoiYA/yC2icaLsvMlRFxan37JdQ+oXIMsBp4mto7jj6rk33+FLAbcHH9HfTG7MMXIOtkn3cqnelzZt4VET8HVgCbgG9lZsOPPfYFnfx3PhtYEBG/pXaY5ZOZ2WevuhoRVwDTgOER0QJ8GhgMPTd++c1nSVKhPxxKkiR1gcEgSSoYDJKkgsEgSSoYDJKkgsEgSSoYDJKkgsEgdYOI+FJE3BkRX212LdKO2um/+Sz1tIh4NXB4Zo7rZPuBmfl8D5clbTe/+SztgIh4HXAttTdZD1K7LMEmYAzwSmrXY/pZRPyA2qWRXw/8e2Z+tjkVSx1zxiDtgMxcFRGXA2sy81sRcRfwk8x8d0QcAXwZ+BkwAbgrM49sZr1SZ3iOQdpxE4DbI+LF1C7n/S/19XdSu0nOEOAVwGeaVJ/UJQaDtOPGAyuBA4B7MnNDff2B1O5JPJ7afXj77O0l1b94KEnaARGxK/BcZj4dEZOA0fUZwkBqM4dPUJtRrGhimVKXOGOQdswBwOb7G0wC/g9wPbUbynwjM2/EYFAf46eSpG5Sv23mhzNzVbNrkXaEwSB1k4j4IzAqMzc1uxZpRxgMkqSC5xgkSQWDQZJUMBgkSQWDQZJUMBgkSQWDQZJUMBgkSQWDQZJU+P9W8khLr9cHTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_best = MLPClassifier(hidden_layer_sizes=(best_layer),solver=best_solver,activation=best_activation,\n",
    "                       learning_rate=best_learn_rate, learning_rate_init=best_rate,\n",
    "                       random_state=1, max_iter=5000)\n",
    "\n",
    "clf_best.fit(Xtrain_scaled, y_train)\n",
    "\n",
    "# Look at the weights\n",
    "print([coef.shape for coef in clf_best.coefs_])\n",
    "\n",
    "y_pred_best = clf_best.predict(Xtest_scaled)\n",
    "\n",
    "# accuracy of the classifier\n",
    "accuracy_best = accuracy_score(y_test,y_pred_best)\n",
    "print('accuracy cross_validated:',accuracy_best)\n",
    "print('accuracy basic NN:',accuracy)\n",
    "\n",
    "proba_best = clf_best.predict_proba(Xtest_scaled)[:,1]\n",
    "fpr_best, tpr_best, thresh_best = roc_curve(y_test, proba_best)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(fpr_best, tpr_best,color='red',label='CV NN')\n",
    "plt.plot(fpr,tpr,color='black',label='basic NN')\n",
    "plt.xlabel(r'$fpr$')\n",
    "plt.ylabel(r'$tpr$')\n",
    "plt.title('ROC curve best NN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stufff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_func(y_true, y_m):\n",
    "    N = len(y_true)\n",
    "    return np.sqrt(1/N * np.sum((y_true-y_m)**2)) \n",
    "\n",
    "def cross_validation(X,y,model,split_method):\n",
    "    \"computes and returns the cross validation error and the training error, given the datasets and the model to validate\"\n",
    "    \n",
    "    split = split_method # sample splitting\n",
    "    \n",
    "    err_train_i = []\n",
    "    err_cv_i = []\n",
    "    \n",
    "    # iterating over the n_splits\n",
    "    for train, test in split.split(X):\n",
    "        \n",
    "        # define the model given the splitted data\n",
    "        model.fit(X[train],y[train]) \n",
    "        \n",
    "        #define the variables to compute the errors\n",
    "        y_train = model.predict(X[train])\n",
    "        y_true_train = y[train]\n",
    "        \n",
    "        y_cv = model.predict(X[test])\n",
    "        y_true_cv = y[test]\n",
    "    \n",
    "        # compute the errors on the training and cross-validation set for a given set\n",
    "        err_train_i.append(error_func(y_true_train,y_train)) # compute the error on the training set\n",
    "        err_cv_i.append(error_func(y_true_cv,y_cv)) # compute the error on the validation set\n",
    "   \n",
    "    err_train = np.mean(err_train_i)\n",
    "    err_cv = np.mean(err_cv_i)\n",
    "    \n",
    "    return err_train, err_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = np.arange(2,20)\n",
    "\n",
    "rms_val = np.zeros(len(n_layers))\n",
    "rms_train = np.zeros(len(n_layers))\n",
    "\n",
    "for n in n_layers:\n",
    "    n_splits = 5\n",
    "    split_method = KFold(n_splits)\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=(n),solver='sgd',activation='logistic', # grad descent solver and sigmoid activation funct\n",
    "                           learning_rate='constant', learning_rate_init=0.001,\n",
    "                           random_state=1, max_iter=5000)\n",
    "    \n",
    "    rms_train[n-2],rms_val[n-2] = cross_validation(Xtrain_scaled,y_train,model,split_method)\n",
    "\n",
    "best_Nlayers = n_layers[np.argmin(rms_val)]\n",
    "print(best_Nlayers)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.plot(n_layers,rms_val,label='validation',color='red')\n",
    "plt.plot(n_layers,rms_train,label='training',color='black',ls='--')\n",
    "plt.ylabel('rms error')\n",
    "plt.xlabel('$N_{layers}$')\n",
    "plt.title('Best N-layers cross-validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
